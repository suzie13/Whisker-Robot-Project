{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 17:46:45.036083: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:46:45.036275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:46:45.050206: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:46:45.050393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:46:45.050529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:46:45.050653: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "# import cv2\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"denser_data_collection.csv\" #\"denser_data_collection_marker.csv\" #\"data_collection.csv\"\n",
    "columns = ['Serial_no','Timestamp', 'x_actual', 'y_actual', 'direction', 'x_step', 'y_step']\n",
    "data_df = pd.read_csv(csv_file, header=None, names = columns)\n",
    "\n",
    "serial_numbers = data_df['Serial_no'].astype(str).apply(lambda x: int(x.split(',')[0]))\n",
    "\n",
    "image_folder = \"output_images_denser\" #\"output_images_denser_marker\" #\"cropped_noedges_new\" #\"output_images_new\" #\"images_resized_500\"\n",
    "imagess = []\n",
    "parsed_custom_info = []\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "data_df['direction'] = le.fit_transform(data_df['direction'])\n",
    "\n",
    "# for index, info in enumerate(data_df[0]):\n",
    "\n",
    "\n",
    "\n",
    "# serial_number = data_df['Serial_no.']\n",
    "serial_numbers = set(data_df['Serial_no'])\n",
    "\n",
    "date_time = data_df['Timestamp']\n",
    "x_coordinate = data_df['x_actual']\n",
    "y_coordinate = data_df['y_actual']\n",
    "direction = data_df['direction']\n",
    "x_step = data_df['x_step']\n",
    "y_step = data_df['y_step']\n",
    "\n",
    "# data_df = data_df[3000:]\n",
    "\n",
    "image_files = os.listdir(image_folder)\n",
    "imagess = []\n",
    "\n",
    "contact = 0\n",
    "non_contact = 1\n",
    "\n",
    "for row in data_df.itertuples(index=False, name='data_df'):\n",
    "    serial_number = row.Serial_no\n",
    "    date_time = row.Timestamp\n",
    "    x_coordinate = row.x_actual\n",
    "    y_coordinate = row.y_actual\n",
    "    direction = row.direction\n",
    "    x_step = row.x_step\n",
    "    y_step = row.y_step\n",
    "\n",
    "\n",
    "    # if ~(pd.isna(x_coordinate) and pd.isna(y_coordinate)):\n",
    "    # if ~(pd.isnull(x_coordinate) and pd.isnull(y_coordinate)):\n",
    "    # if pd.notnull(x_coordinate) and pd.notnull(y_coordinate):\n",
    "    # if not math.isnan(x_coordinate) and not math.isnan(y_coordinate):\n",
    "    # if not x_coordinate.empty and not y_coordinate.empty:\n",
    "    # if not(direction == 0 and x_coordinate > 4.49) or not(direction == 1 and y_coordinate < -18.81):\n",
    "\n",
    "    ############################## contact data only\n",
    "    if pd.notnull(x_coordinate) and pd.notnull(y_coordinate) and \\\n",
    "        not((direction == 0 and (x_coordinate > 4.49 or x_coordinate < -12.5)) \\\n",
    "               or (direction == 1 and (x_coordinate < -18.81 or x_coordinate > -3.075))):\n",
    "            matching_files = [filename for filename in image_files if filename.startswith(str(serial_number))]\n",
    "            if matching_files:\n",
    "                image_name = matching_files[0]  # Assuming there is only one matching file\n",
    "                image_path = os.path.join(image_folder, image_name)\n",
    "                image = cv2.imread(image_path)\n",
    "                # if image is not None: \n",
    "                imagess.append(image)\n",
    "                parsed_custom_info.append([x_coordinate, y_coordinate, direction, contact])\n",
    "\n",
    "    elif pd.notnull(x_coordinate) and pd.notnull(y_coordinate) and \\\n",
    "        ((direction == 0 and (x_coordinate > 4.49 or x_coordinate < -12.5)) \\\n",
    "               or (direction == 1 and (x_coordinate < -18.81 or x_coordinate > -3.075))):\n",
    "            matching_files = [filename for filename in image_files if filename.startswith(str(serial_number))]\n",
    "            if matching_files:\n",
    "                image_name = matching_files[0]  # Assuming there is only one matching file\n",
    "                image_path = os.path.join(image_folder, image_name)\n",
    "                image = cv2.imread(image_path)\n",
    "                # if image is not None: \n",
    "                imagess.append(image)\n",
    "                parsed_custom_info.append([x_coordinate, y_coordinate, direction, non_contact])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition = data_df['direction'] == 0 and (data_df['x_coordinate'] > 4.49 or data_df['x_coordinate'] < -12.5)\n",
    "# condition = pd.notnull(x_coordinate) and pd.notnull(y_coordinate) and \\\n",
    "#         not((direction == 0 and (x_coordinate > 4.49 or x_coordinate < -12.5)) \\\n",
    "#                or (direction == 1 and (x_coordinate < -18.81 or x_coordinate > -3.075)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # condition = data_df['direction'] == 25\n",
    "# name_to_fill1 = 'contact'\n",
    "# name_to_fill2 = 'non-contact'\n",
    "\n",
    "# # data_df['Mode_of_Interaction'] = name_to_fill1  # Fill the entire column with the default name\n",
    "# data_df.loc[condition, 'Mode_of_Interaction'] = name_to_fill1  # Fill only the rows where the condition is True\n",
    "# data_df.loc[~condition, 'Mode_of_Interaction'] = name_to_fill2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_value = data_df['column_name'].max()\n",
    "\n",
    "# # Find the minimum value\n",
    "# min_value = data_df['column_name'].min()\n",
    "\n",
    "# print(\"Maximum value:\", max_value)\n",
    "# print(\"Minimum value:\", min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15710, 7)\n"
     ]
    }
   ],
   "source": [
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = data_df.groupby(['direction'])\n",
    "# df1 = grouped.get_group((0))\n",
    "# df2 = grouped.get_group((1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1960, 7)\n",
      "(1970, 7)\n"
     ]
    }
   ],
   "source": [
    "# print(df1.shape)\n",
    "# print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# print(data_df['direction'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug  1 15:01:40 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX 6000...  On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 30%   45C    P3    36W / 300W |      5MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX 6000...  On   | 00000000:61:00.0 Off |                  Off |\n",
      "| 48%   71C    P2   249W / 300W |  47197MiB / 49140MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A   1071170      C   python3                         47192MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(imagess, parsed_custom_info))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend import set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 17:50:27.017577: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:50:27.017739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:50:27.017870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:50:27.017986: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:50:27.018100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:50:27.018216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:50:27.591870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:50:27.592049: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:50:27.592188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:50:27.592318: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:50:27.592452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:50:27.592568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11320 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "2023-07-31 17:50:27.592951: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:50:27.593061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 45843 MB memory:  -> device: 1, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:61:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "# config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15036\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split the dataset\n",
    "np.random.shuffle(data)\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(data) * train_ratio)\n",
    "\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "X_train = [item[0] for item in train_data]\n",
    "Y_train = [item[1] for item in train_data]\n",
    "\n",
    "X_test = [item[0] for item in test_data]\n",
    "Y_test = [item[1] for item in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = np.array(X_test)\n",
    "X_train1 = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = X_test1.astype('float32')\n",
    "X_train1 = X_train1.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_nan = data_df['x_actual'].isnull().values.any()\n",
    "# print(check_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if np.isnan(parsed_custom_info).any():\n",
    "    # print(\"The array contains NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(parsed_custom_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_train:  (12028, 1080, 1920, 3)\n",
      "Shape Y_train:  (12028, 4)\n",
      "Shape X_test:  (3008, 1080, 1920, 3)\n",
      "Shape Y_test:  (3008, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape X_train: \", np.shape(X_train1))\n",
    "print(\"Shape Y_train: \", np.shape(Y_train))\n",
    "\n",
    "print(\"Shape X_test: \", np.shape(X_test1))\n",
    "print(\"Shape Y_test: \", np.shape(Y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train = np.nan_to_num(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12028"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375.875\n"
     ]
    }
   ],
   "source": [
    "n_batches = len(X_train1) / 32\n",
    "print(n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n"
     ]
    }
   ],
   "source": [
    "n_batches = math.ceil(n_batches)\n",
    "print(n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from the latest checkpoint: checkpoints/weights_epoch_0040.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 15:28:37.980812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 15:28:37.981017: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 15:28:37.981155: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 15:28:37.981280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 15:28:37.981403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 15:28:37.981525: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 15:28:37.981703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 15:28:37.981833: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 15:28:37.981959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 15:28:37.982065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46476 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "2023-07-29 15:28:37.982101: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 15:28:37.982204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46479 MB memory:  -> device: 1, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:61:00.0, compute capability: 8.9\n",
      "2023-07-29 15:28:37.994368: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-07-29 15:28:38.003514: W tensorflow/c/c_api.cc:291] Operation '{name:'dense_1/bias/Assign' id:105 op device:{requested: '', assigned: ''} def:{{{node dense_1/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_1/bias, dense_1/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(1080, 1920, 3), kernel_regularizer=tf.keras.regularizers.l2(0.001))) #(1080, 1920, 3) #(1080, 1350, 3)\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(Dense(4))  # Output layer with 4 units for regression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "# Define the checkpoint path and directory\n",
    "checkpoint_path = \"checkpoints/weights_epoch_{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Check if a checkpoint file exists, if yes, load the weights\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "if latest is not None:\n",
    "    print(\"Loading weights from the latest checkpoint:\", latest)\n",
    "    model.load_weights(latest)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#    #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from the latest checkpoint: checkpoints/weights_epoch_0184.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 17:52:54.208119: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:52:54.208345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:52:54.208492: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:52:54.208620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:52:54.208744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:52:54.208869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:52:54.209049: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:52:54.209178: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:52:54.209303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:52:54.209408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11320 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "2023-07-31 17:52:54.209446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-31 17:52:54.209548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 45843 MB memory:  -> device: 1, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:61:00.0, compute capability: 8.9\n",
      "2023-07-31 17:52:54.222870: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-07-31 17:52:54.233173: W tensorflow/c/c_api.cc:291] Operation '{name:'dense/bias/Assign' id:84 op device:{requested: '', assigned: ''} def:{{{node dense/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense/bias, dense/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12028 samples\n",
      "Epoch 186/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 17:52:57.214292: W tensorflow/c/c_api.cc:291] Operation '{name:'loss/AddN_1' id:162 op device:{requested: '', assigned: ''} def:{{{node loss/AddN_1}} = AddN[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](loss/mul, loss/AddN)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-07-31 17:53:09.023894: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.89GiB (rounded to 8468905984)requested by op conv2d/Relu\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-07-31 17:53:09.023962: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-07-31 17:53:09.023975: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 17, Chunks in use: 15. 4.2KiB allocated for chunks. 3.8KiB in use in bin. 956B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.023983: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 3, Chunks in use: 1. 1.5KiB allocated for chunks. 512B in use in bin. 512B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.023991: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 2, Chunks in use: 2. 2.2KiB allocated for chunks. 2.2KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2023-07-31 17:53:09.023999: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 3, Chunks in use: 2. 9.2KiB allocated for chunks. 7.0KiB in use in bin. 6.8KiB client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024005: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024011: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024018: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 1, Chunks in use: 0. 17.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024024: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024032: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 3, Chunks in use: 2. 216.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024039: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 2, Chunks in use: 2. 288.0KiB allocated for chunks. 288.0KiB in use in bin. 288.0KiB client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024045: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024050: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024057: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 0. 1.47MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024062: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024068: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024074: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024079: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024085: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024090: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024097: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 139.25MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024104: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 6, Chunks in use: 3. 8.86GiB allocated for chunks. 4.61GiB in use in bin. 4.61GiB client-requested in use in bin.\n",
      "2023-07-31 17:53:09.024114: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 7.89GiB was 256.00MiB, Chunk State: \n",
      "2023-07-31 17:53:09.024124: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 1.00GiB | Requested Size: 759.38MiB | in_use: 0 | bin_num: 20\n",
      "2023-07-31 17:53:09.024133: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 1.26GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 759.38MiB | Requested Size: 759.38MiB | in_use: 1 | bin_num: -1\n",
      "2023-07-31 17:53:09.024139: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 2.00GiB | Requested Size: 1.93GiB | in_use: 0 | bin_num: 20\n",
      "2023-07-31 17:53:09.024144: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 4294967296\n",
      "2023-07-31 17:53:09.024153: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1900000000 of size 2074476544 next 32\n",
      "2023-07-31 17:53:09.024158: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f197ba60000 of size 2074476544 next 36\n",
      "2023-07-31 17:53:09.024164: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f19f74c0000 of size 146014208 next 18446744073709551615\n",
      "2023-07-31 17:53:09.024169: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 2147483648\n",
      "2023-07-31 17:53:09.024174: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1a0a000000 of size 796262400 next 28\n",
      "2023-07-31 17:53:09.024179: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1a39760000 of size 1351221248 next 18446744073709551615\n",
      "2023-07-31 17:53:09.024183: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 2147483648\n",
      "2023-07-31 17:53:09.024188: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1b10000000 of size 2147483648 next 18446744073709551615\n",
      "2023-07-31 17:53:09.024193: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 1073741824\n",
      "2023-07-31 17:53:09.024198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1b90000000 of size 1073741824 next 18446744073709551615\n",
      "2023-07-31 17:53:09.024202: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 2097152\n",
      "2023-07-31 17:53:09.024208: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac00000 of size 1280 next 1\n",
      "2023-07-31 17:53:09.024213: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac00500 of size 256 next 2\n",
      "2023-07-31 17:53:09.024218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac00600 of size 256 next 3\n",
      "2023-07-31 17:53:09.024223: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac00700 of size 256 next 4\n",
      "2023-07-31 17:53:09.024227: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac00800 of size 256 next 5\n",
      "2023-07-31 17:53:09.024232: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac00900 of size 256 next 6\n",
      "2023-07-31 17:53:09.024237: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac00a00 of size 256 next 7\n",
      "2023-07-31 17:53:09.024241: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac00b00 of size 256 next 8\n",
      "2023-07-31 17:53:09.024246: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac00c00 of size 256 next 9\n",
      "2023-07-31 17:53:09.024251: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f226ac00d00 of size 256 next 10\n",
      "2023-07-31 17:53:09.024256: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac00e00 of size 256 next 11\n",
      "2023-07-31 17:53:09.024260: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac00f00 of size 256 next 12\n",
      "2023-07-31 17:53:09.024266: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac01000 of size 73728 next 13\n",
      "2023-07-31 17:53:09.024271: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac13000 of size 1024 next 14\n",
      "2023-07-31 17:53:09.024275: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac13400 of size 256 next 15\n",
      "2023-07-31 17:53:09.024281: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f226ac13500 of size 512 next 17\n",
      "2023-07-31 17:53:09.024286: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac13700 of size 256 next 18\n",
      "2023-07-31 17:53:09.024291: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f226ac13800 of size 256 next 19\n",
      "2023-07-31 17:53:09.024296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac13900 of size 512 next 20\n",
      "2023-07-31 17:53:09.024301: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac13b00 of size 256 next 22\n",
      "2023-07-31 17:53:09.024305: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f226ac13c00 of size 512 next 37\n",
      "2023-07-31 17:53:09.024310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac13e00 of size 256 next 38\n",
      "2023-07-31 17:53:09.024315: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac13f00 of size 256 next 40\n",
      "2023-07-31 17:53:09.024320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f226ac14000 of size 2304 next 23\n",
      "2023-07-31 17:53:09.024324: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac14900 of size 147456 next 24\n",
      "2023-07-31 17:53:09.024329: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac38900 of size 3584 next 26\n",
      "2023-07-31 17:53:09.024334: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac39700 of size 73728 next 39\n",
      "2023-07-31 17:53:09.024339: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f226ac4b700 of size 73728 next 29\n",
      "2023-07-31 17:53:09.024344: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac5d700 of size 3584 next 30\n",
      "2023-07-31 17:53:09.024348: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f226ac5e500 of size 17408 next 34\n",
      "2023-07-31 17:53:09.024353: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f226ac62900 of size 147456 next 35\n",
      "2023-07-31 17:53:09.024358: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f226ac86900 of size 1545984 next 18446744073709551615\n",
      "2023-07-31 17:53:09.024363: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-07-31 17:53:09.024369: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 15 Chunks of size 256 totalling 3.8KiB\n",
      "2023-07-31 17:53:09.024375: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 512 totalling 512B\n",
      "2023-07-31 17:53:09.024380: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1024 totalling 1.0KiB\n",
      "2023-07-31 17:53:09.024386: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-07-31 17:53:09.024391: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 3584 totalling 7.0KiB\n",
      "2023-07-31 17:53:09.024397: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 73728 totalling 144.0KiB\n",
      "2023-07-31 17:53:09.024402: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 147456 totalling 288.0KiB\n",
      "2023-07-31 17:53:09.024408: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 796262400 totalling 759.38MiB\n",
      "2023-07-31 17:53:09.024414: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 2074476544 totalling 3.86GiB\n",
      "2023-07-31 17:53:09.024419: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 4.61GiB\n",
      "2023-07-31 17:53:09.024424: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 9665773568 memory_limit_: 11870666752 available bytes: 2204893184 curr_region_allocation_bytes_: 8589934592\n",
      "2023-07-31 17:53:09.024434: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                     11870666752\n",
      "InUse:                      4945671680\n",
      "MaxInUse:                   7093247232\n",
      "NumAllocs:                          42\n",
      "MaxAllocSize:               2147483648\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-07-31 17:53:09.024443: W tensorflow/tsl/framework/bfc_allocator.cc:492] *******************************************_*********______________________________________________*\n",
      "2023-07-31 17:53:09.024478: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops_fused_impl.h:766 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,32,1078,1918] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,32,1078,1918] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[training/Adam/clip_by_norm_4/truediv/_83]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,32,1078,1918] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_731821/2248110198.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m history = model.fit(X_train1, Y_train, \n\u001b[0m\u001b[1;32m     53\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Start from the next epoch after the latest checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m         return func.fit(\n\u001b[0m\u001b[1;32m    855\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         return fit_loop(\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4579\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4581\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4582\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4583\u001b[0m         output_structure = tf.nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1482\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,32,1078,1918] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[training/Adam/clip_by_norm_4/truediv/_83]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,32,1078,1918] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(1080, 1920, 3), kernel_regularizer=tf.keras.regularizers.l2(0.001))) #(1080, 1920, 3) #(1080, 1350, 3)\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(Dense(4))  # Output layer with 4 units for regression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the checkpoint path and directory\n",
    "checkpoint_path = \"checkpoints/weights_epoch_{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Check if a checkpoint file exists, if yes, load the weights\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "if latest is not None:\n",
    "    print(\"Loading weights from the latest checkpoint:\", latest)\n",
    "    model.load_weights(latest)\n",
    "\n",
    "# Define batch size and calculate the number of batches per epoch\n",
    "batch_size = 32\n",
    "# n_batches = len(X_train1) // batch_size\n",
    "\n",
    "# Create a callback that saves the model's weights only at even epochs\n",
    "def save_model_at_even_epochs(epoch, logs):\n",
    "    if epoch % 2 == 0:\n",
    "        model.save_weights(checkpoint_path.format(epoch=epoch))\n",
    "\n",
    "cp_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=save_model_at_even_epochs)\n",
    "\n",
    "# Start training from the next epoch after the latest checkpoint\n",
    "start_epoch = 0\n",
    "if latest is not None:\n",
    "    # Extract the epoch number from the checkpoint path\n",
    "    start_epoch = int(latest.split(\"_\")[-1].split(\".\")[0]) + 1\n",
    "\n",
    "# Start training\n",
    "history = model.fit(X_train1, Y_train, \n",
    "                    epochs=300,\n",
    "                    initial_epoch=start_epoch,  # Start from the next epoch after the latest checkpoint\n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[cp_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making preictions by loading the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-07-29 15:28:53.663538: W tensorflow/c/c_api.cc:291] Operation '{name:'dense_1/BiasAdd' id:110 op device:{requested: '', assigned: ''} def:{{{node dense_1/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_1/MatMul, dense_1/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-07-29 15:28:54.855554: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[-13.773119   -24.760492     0.30121353   0.68982846]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 15:28:55.283879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "# predictions = model.predict(X_new)\n",
    "sample_index = 5  # Replace with the index of the desired sample\n",
    "\n",
    "sample = np.expand_dims(X_test1[sample_index], axis=0) \n",
    "\n",
    "y_pred = model.predict(sample)\n",
    "\n",
    "print('Prediction:', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-14.24978661 -24.63892009   0.           1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions by loading a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model from the .h5 file\n",
    "model_path = \"path/to/your/model.h5\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Assuming you have new data for prediction, you can use model.predict()\n",
    "# For example, if you have new data in X_new, you can make predictions as follows:\n",
    "# Load your new data for prediction, replace X_new with your data\n",
    "X_new = ...\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "# Print or use the predictions as required\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from the latest checkpoint: checkpoints/weights_epoch_0028.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 11:11:17.668792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 11:11:17.668995: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 11:11:17.669136: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 11:11:17.669262: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 11:11:17.669386: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 11:11:17.669511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 11:11:17.669694: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 11:11:17.669826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 11:11:17.669954: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 11:11:17.670062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46476 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "2023-07-29 11:11:17.670098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-29 11:11:17.670204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46479 MB memory:  -> device: 1, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:61:00.0, compute capability: 8.9\n",
      "2023-07-29 11:11:17.682822: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-07-29 11:11:17.713781: W tensorflow/c/c_api.cc:291] Operation '{name:'dense_1/bias/Assign' id:127 op device:{requested: '', assigned: ''} def:{{{node dense_1/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_1/bias, dense_1/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12028 samples\n",
      "Epoch 30/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 11:11:20.357336: W tensorflow/c/c_api.cc:291] Operation '{name:'loss/AddN_1' id:184 op device:{requested: '', assigned: ''} def:{{{node loss/AddN_1}} = AddN[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](loss/mul, loss/AddN)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-07-29 11:11:21.968436: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2023-07-29 11:11:22.626128: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700\n",
      "2023-07-29 11:11:24.198530: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12028/12028 [==============================] - 648s 54ms/sample - loss: 8.0001\n",
      "Epoch 31/300\n",
      "12000/12028 [============================>.] - ETA: 1s - loss: 7.0954\n",
      "Epoch 31: saving model to checkpoints/weights_epoch_0031.ckpt\n",
      "12028/12028 [==============================] - 634s 53ms/sample - loss: 7.0972\n",
      "Epoch 32/300\n",
      "12028/12028 [==============================] - 629s 52ms/sample - loss: 6.6084\n",
      "Epoch 33/300\n",
      "12000/12028 [============================>.] - ETA: 1s - loss: 6.2037\n",
      "Epoch 33: saving model to checkpoints/weights_epoch_0033.ckpt\n",
      "12028/12028 [==============================] - 630s 52ms/sample - loss: 6.2049\n",
      "Epoch 34/300\n",
      "12028/12028 [==============================] - 628s 52ms/sample - loss: 6.0901\n",
      "Epoch 35/300\n",
      "  288/12028 [..............................] - ETA: 10:11 - loss: 4.9488"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4133662/2997381417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m history = model.fit(X_train1, Y_train, \n\u001b[0m\u001b[1;32m     61\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m         return func.fit(\n\u001b[0m\u001b[1;32m    855\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         return fit_loop(\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4579\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4581\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4582\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4583\u001b[0m         output_structure = tf.nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1482\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(1080, 1920, 3), kernel_regularizer=tf.keras.regularizers.l2(0.001))) #(1080, 1920, 3) #(1080, 1350, 3)\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(Dense(4))  # Output layer with 4 units for regression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = \"checkpoints/weights_epoch_{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# if os.path.exists(checkpoint_path.format(epoch=28)):\n",
    "#     model.load_weights(checkpoint_path.format(epoch=28))\n",
    "\n",
    "# Check if a checkpoint file exists, if yes, load the weights\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "if latest is not None:\n",
    "    print(\"Loading weights from the latest checkpoint:\", latest)\n",
    "    model.load_weights(latest)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Calculate the number of batches per epoch\n",
    "import math\n",
    "n_batches = len(X_train1) / batch_size\n",
    "# n_batches = math.ceil(n_batches)    # round up the number of batches to the nearest whole integer\n",
    "\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=math.ceil(2*n_batches)) #len(X_train1) / batch_size\n",
    "\n",
    "\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "# model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# Start training from the next epoch after the latest checkpoint\n",
    "start_epoch = 0\n",
    "if latest is not None:\n",
    "    # Extract the epoch number from the checkpoint path\n",
    "    start_epoch = int(latest.split(\"_\")[-1].split(\".\")[0]) + 1\n",
    "\n",
    "history = model.fit(X_train1, Y_train, \n",
    "          epochs=300,\n",
    "          initial_epoch=start_epoch,\n",
    "          batch_size=batch_size, \n",
    "          callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Train on 12028 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 22:28:53.265573: W tensorflow/c/c_api.cc:291] Operation '{name:'training_2/Adam/dense_3/bias/v/Assign' id:1079 op device:{requested: '', assigned: ''} def:{{{node training_2/Adam/dense_3/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_2/Adam/dense_3/bias/v, training_2/Adam/dense_3/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-07-28 22:28:55.289514: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.89GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32/12028 [..............................] - ETA: 15:14 - loss: 224.3641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 22:29:06.326863: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.92GiB (rounded to 4209942528)requested by op training_2/Adam/gradients/gradients/conv2d_4/BiasAdd_grad/BiasAddGrad\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-07-28 22:29:06.326907: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-07-28 22:29:06.326922: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 104, Chunks in use: 103. 26.0KiB allocated for chunks. 25.8KiB in use in bin. 8.1KiB client-requested in use in bin.\n",
      "2023-07-28 22:29:06.326930: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 1, Chunks in use: 0. 512B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.326938: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 10, Chunks in use: 9. 10.2KiB allocated for chunks. 9.2KiB in use in bin. 9.0KiB client-requested in use in bin.\n",
      "2023-07-28 22:29:06.326945: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 9, Chunks in use: 9. 31.5KiB allocated for chunks. 31.5KiB in use in bin. 30.4KiB client-requested in use in bin.\n",
      "2023-07-28 22:29:06.326952: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.326957: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.326964: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 1, Chunks in use: 0. 31.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.326970: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.326977: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 9, Chunks in use: 9. 648.0KiB allocated for chunks. 648.0KiB in use in bin. 648.0KiB client-requested in use in bin.\n",
      "2023-07-28 22:29:06.326984: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 10, Chunks in use: 10. 1.55MiB allocated for chunks. 1.55MiB in use in bin. 1.41MiB client-requested in use in bin.\n",
      "2023-07-28 22:29:06.326990: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.326995: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.327001: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.327007: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.327013: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.327018: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.327024: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.327033: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.327039: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.327045: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 138.97MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:06.327053: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 21, Chunks in use: 14. 45.25GiB allocated for chunks. 34.13GiB in use in bin. 33.88GiB client-requested in use in bin.\n",
      "2023-07-28 22:29:06.327060: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 3.92GiB was 256.00MiB, Chunk State: \n",
      "2023-07-28 22:29:06.327072: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 278.50MiB | Requested Size: 759.38MiB | in_use: 0 | bin_num: 20, prev:   Size: 1.93GiB | Requested Size: 1.93GiB | in_use: 1 | bin_num: -1\n",
      "2023-07-28 22:29:06.327080: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 759.38MiB | Requested Size: 759.38MiB | in_use: 0 | bin_num: 20, next:   Size: 759.38MiB | Requested Size: 759.38MiB | in_use: 1 | bin_num: -1\n",
      "2023-07-28 22:29:06.327090: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 1000.81MiB | Requested Size: 1000.81MiB | in_use: 0 | bin_num: 20, prev:   Size: 1.93GiB | Requested Size: 1.93GiB | in_use: 1 | bin_num: -1, next:   Size: 3.92GiB | Requested Size: 3.92GiB | in_use: 1 | bin_num: -1\n",
      "2023-07-28 22:29:06.327098: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 1.37GiB | Requested Size: 989.19MiB | in_use: 0 | bin_num: 20, prev:   Size: 3.92GiB | Requested Size: 3.92GiB | in_use: 1 | bin_num: -1\n",
      "2023-07-28 22:29:06.327107: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 1.93GiB | Requested Size: 1000.81MiB | in_use: 0 | bin_num: 20, prev:   Size: 7.89GiB | Requested Size: 7.89GiB | in_use: 1 | bin_num: -1, next:   Size: 2.08GiB | Requested Size: 1.97GiB | in_use: 1 | bin_num: -1\n",
      "2023-07-28 22:29:06.327114: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 1.97GiB | Requested Size: 1.97GiB | in_use: 0 | bin_num: 20, next:   Size: 1.97GiB | Requested Size: 1.97GiB | in_use: 1 | bin_num: -1\n",
      "2023-07-28 22:29:06.327122: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 3.85GiB | Requested Size: 1000.81MiB | in_use: 0 | bin_num: 20, prev:   Size: 1.97GiB | Requested Size: 1.97GiB | in_use: 1 | bin_num: -1, next:   Size: 1.93GiB | Requested Size: 1.93GiB | in_use: 1 | bin_num: -1\n",
      "2023-07-28 22:29:06.327127: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 14370471936\n",
      "2023-07-28 22:29:06.327133: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f0074000000 of size 796262400 next 116\n",
      "2023-07-28 22:29:06.327140: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f00a3760000 of size 796262400 next 122\n",
      "2023-07-28 22:29:06.327145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f00d2ec0000 of size 8468905984 next 147\n",
      "2023-07-28 22:29:06.327150: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f02cbb54000 of size 2074476544 next 149\n",
      "2023-07-28 22:29:06.327155: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f03475b4000 of size 2234564608 next 18446744073709551615\n",
      "2023-07-28 22:29:06.327160: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 17179869184\n",
      "2023-07-28 22:29:06.327165: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f040c000000 of size 2117226496 next 157\n",
      "2023-07-28 22:29:06.327171: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f048a325000 of size 2117226496 next 146\n",
      "2023-07-28 22:29:06.327177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f050864a000 of size 4136632320 next 148\n",
      "2023-07-28 22:29:06.327182: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f05fef4a000 of size 2074476544 next 162\n",
      "2023-07-28 22:29:06.327188: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f067a9aa000 of size 1049427968 next 167\n",
      "2023-07-28 22:29:06.327193: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f06b927a000 of size 4209942528 next 156\n",
      "2023-07-28 22:29:06.327198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f07b4164000 of size 1474936832 next 18446744073709551615\n",
      "2023-07-28 22:29:06.327202: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 8589934592\n",
      "2023-07-28 22:29:06.327207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f08f2000000 of size 2074476544 next 100\n",
      "2023-07-28 22:29:06.327212: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f096da60000 of size 2074476544 next 45\n",
      "2023-07-28 22:29:06.327217: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f09e94c0000 of size 2074476544 next 125\n",
      "2023-07-28 22:29:06.327221: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f0a64f20000 of size 2074476544 next 120\n",
      "2023-07-28 22:29:06.327226: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f0ae0980000 of size 292028416 next 18446744073709551615\n",
      "2023-07-28 22:29:06.327231: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 4294967296\n",
      "2023-07-28 22:29:06.327236: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f0afc000000 of size 2074476544 next 47\n",
      "2023-07-28 22:29:06.327240: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f0b77a60000 of size 2074476544 next 77\n",
      "2023-07-28 22:29:06.327245: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f0bf34c0000 of size 147456 next 152\n",
      "2023-07-28 22:29:06.327250: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f0bf34e4000 of size 147456 next 166\n",
      "2023-07-28 22:29:06.327255: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f0bf3508000 of size 145719296 next 18446744073709551615\n",
      "2023-07-28 22:29:06.327260: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 2147483648\n",
      "2023-07-28 22:29:06.327265: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f0c30000000 of size 2147483648 next 18446744073709551615\n",
      "2023-07-28 22:29:06.327269: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 2147483648\n",
      "2023-07-28 22:29:06.327274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f0cb6000000 of size 2147483648 next 18446744073709551615\n",
      "2023-07-28 22:29:06.327279: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 2097152\n",
      "2023-07-28 22:29:06.327284: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00000 of size 1280 next 1\n",
      "2023-07-28 22:29:06.327289: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00500 of size 256 next 2\n",
      "2023-07-28 22:29:06.327294: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00600 of size 256 next 3\n",
      "2023-07-28 22:29:06.327299: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00700 of size 256 next 4\n",
      "2023-07-28 22:29:06.327304: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00800 of size 256 next 5\n",
      "2023-07-28 22:29:06.327308: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00900 of size 256 next 6\n",
      "2023-07-28 22:29:06.327313: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00a00 of size 256 next 7\n",
      "2023-07-28 22:29:06.327318: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00b00 of size 256 next 8\n",
      "2023-07-28 22:29:06.327322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00c00 of size 256 next 9\n",
      "2023-07-28 22:29:06.327327: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00d00 of size 256 next 10\n",
      "2023-07-28 22:29:06.327333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00e00 of size 256 next 11\n",
      "2023-07-28 22:29:06.327338: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00f00 of size 256 next 12\n",
      "2023-07-28 22:29:06.327342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c01000 of size 256 next 13\n",
      "2023-07-28 22:29:06.327347: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c01100 of size 256 next 14\n",
      "2023-07-28 22:29:06.327352: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c01200 of size 3584 next 15\n",
      "2023-07-28 22:29:06.327357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c02000 of size 256 next 16\n",
      "2023-07-28 22:29:06.327362: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c02100 of size 73728 next 17\n",
      "2023-07-28 22:29:06.327367: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c14100 of size 256 next 18\n",
      "2023-07-28 22:29:06.327372: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c14200 of size 147456 next 19\n",
      "2023-07-28 22:29:06.327376: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c38200 of size 256 next 20\n",
      "2023-07-28 22:29:06.327381: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c38300 of size 256 next 21\n",
      "2023-07-28 22:29:06.327386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c38400 of size 256 next 23\n",
      "2023-07-28 22:29:06.327391: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c38500 of size 1024 next 24\n",
      "2023-07-28 22:29:06.327395: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c38900 of size 256 next 25\n",
      "2023-07-28 22:29:06.327400: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c38a00 of size 256 next 26\n",
      "2023-07-28 22:29:06.327405: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c38b00 of size 147456 next 27\n",
      "2023-07-28 22:29:06.327410: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c5cb00 of size 73728 next 28\n",
      "2023-07-28 22:29:06.327415: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c6eb00 of size 3584 next 30\n",
      "2023-07-28 22:29:06.327419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c6f900 of size 1024 next 31\n",
      "2023-07-28 22:29:06.327424: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c6fd00 of size 256 next 32\n",
      "2023-07-28 22:29:06.327429: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c6fe00 of size 256 next 33\n",
      "2023-07-28 22:29:06.327434: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c6ff00 of size 256 next 34\n",
      "2023-07-28 22:29:06.327438: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70000 of size 256 next 35\n",
      "2023-07-28 22:29:06.327443: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70100 of size 256 next 36\n",
      "2023-07-28 22:29:06.327448: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70200 of size 256 next 37\n",
      "2023-07-28 22:29:06.327453: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70300 of size 256 next 38\n",
      "2023-07-28 22:29:06.327457: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70400 of size 256 next 39\n",
      "2023-07-28 22:29:06.327462: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70500 of size 256 next 40\n",
      "2023-07-28 22:29:06.327467: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70600 of size 256 next 41\n",
      "2023-07-28 22:29:06.327471: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70700 of size 256 next 70\n",
      "2023-07-28 22:29:06.327476: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70800 of size 256 next 42\n",
      "2023-07-28 22:29:06.327481: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70900 of size 256 next 88\n",
      "2023-07-28 22:29:06.327486: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70a00 of size 256 next 55\n",
      "2023-07-28 22:29:06.327490: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70b00 of size 256 next 68\n",
      "2023-07-28 22:29:06.327498: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70c00 of size 3584 next 56\n",
      "2023-07-28 22:29:06.327502: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c71a00 of size 3584 next 49\n",
      "2023-07-28 22:29:06.327507: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c72800 of size 3584 next 104\n",
      "2023-07-28 22:29:06.327512: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c73600 of size 256 next 90\n",
      "2023-07-28 22:29:06.327517: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c73700 of size 1024 next 102\n",
      "2023-07-28 22:29:06.327521: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c73b00 of size 256 next 92\n",
      "2023-07-28 22:29:06.327526: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c73c00 of size 256 next 89\n",
      "2023-07-28 22:29:06.327531: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c73d00 of size 1024 next 81\n",
      "2023-07-28 22:29:06.327535: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c74100 of size 3584 next 95\n",
      "2023-07-28 22:29:06.327540: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c74f00 of size 256 next 103\n",
      "2023-07-28 22:29:06.327545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75000 of size 256 next 94\n",
      "2023-07-28 22:29:06.327550: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75100 of size 256 next 98\n",
      "2023-07-28 22:29:06.327554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75200 of size 256 next 106\n",
      "2023-07-28 22:29:06.327559: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75300 of size 256 next 107\n",
      "2023-07-28 22:29:06.327564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75400 of size 256 next 108\n",
      "2023-07-28 22:29:06.327568: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75500 of size 256 next 109\n",
      "2023-07-28 22:29:06.327573: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75600 of size 256 next 110\n",
      "2023-07-28 22:29:06.327578: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75700 of size 256 next 111\n",
      "2023-07-28 22:29:06.327582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75800 of size 256 next 112\n",
      "2023-07-28 22:29:06.327587: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75900 of size 256 next 133\n",
      "2023-07-28 22:29:06.327592: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75a00 of size 256 next 139\n",
      "2023-07-28 22:29:06.327597: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75b00 of size 256 next 115\n",
      "2023-07-28 22:29:06.327601: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75c00 of size 256 next 135\n",
      "2023-07-28 22:29:06.327606: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75d00 of size 256 next 136\n",
      "2023-07-28 22:29:06.327611: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75e00 of size 256 next 145\n",
      "2023-07-28 22:29:06.327615: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1046c75f00 of size 1024 next 154\n",
      "2023-07-28 22:29:06.327620: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76300 of size 256 next 155\n",
      "2023-07-28 22:29:06.327625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76400 of size 256 next 161\n",
      "2023-07-28 22:29:06.327629: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76500 of size 256 next 163\n",
      "2023-07-28 22:29:06.327634: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1046c76600 of size 256 next 150\n",
      "2023-07-28 22:29:06.327639: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76700 of size 256 next 158\n",
      "2023-07-28 22:29:06.327644: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1046c76800 of size 512 next 164\n",
      "2023-07-28 22:29:06.327648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76a00 of size 256 next 117\n",
      "2023-07-28 22:29:06.327654: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76b00 of size 256 next 118\n",
      "2023-07-28 22:29:06.327659: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76c00 of size 256 next 126\n",
      "2023-07-28 22:29:06.327664: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76d00 of size 256 next 113\n",
      "2023-07-28 22:29:06.327668: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76e00 of size 256 next 123\n",
      "2023-07-28 22:29:06.327673: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76f00 of size 256 next 134\n",
      "2023-07-28 22:29:06.327678: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77000 of size 256 next 159\n",
      "2023-07-28 22:29:06.327683: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77100 of size 256 next 160\n",
      "2023-07-28 22:29:06.327687: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77200 of size 256 next 121\n",
      "2023-07-28 22:29:06.327692: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77300 of size 256 next 114\n",
      "2023-07-28 22:29:06.327697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77400 of size 256 next 131\n",
      "2023-07-28 22:29:06.327701: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77500 of size 256 next 137\n",
      "2023-07-28 22:29:06.327706: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77600 of size 256 next 140\n",
      "2023-07-28 22:29:06.327711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77700 of size 256 next 141\n",
      "2023-07-28 22:29:06.327715: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77800 of size 256 next 130\n",
      "2023-07-28 22:29:06.327720: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77900 of size 1024 next 127\n",
      "2023-07-28 22:29:06.327725: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77d00 of size 256 next 128\n",
      "2023-07-28 22:29:06.327730: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77e00 of size 1024 next 132\n",
      "2023-07-28 22:29:06.327734: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c78200 of size 3584 next 144\n",
      "2023-07-28 22:29:06.327739: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c79000 of size 3584 next 119\n",
      "2023-07-28 22:29:06.327744: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c79e00 of size 3584 next 138\n",
      "2023-07-28 22:29:06.327749: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c7ac00 of size 256 next 151\n",
      "2023-07-28 22:29:06.327753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1046c7ad00 of size 32256 next 63\n",
      "2023-07-28 22:29:06.327758: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c82b00 of size 256 next 72\n",
      "2023-07-28 22:29:06.327763: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c82c00 of size 256 next 62\n",
      "2023-07-28 22:29:06.327768: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c82d00 of size 256 next 66\n",
      "2023-07-28 22:29:06.327772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c82e00 of size 256 next 50\n",
      "2023-07-28 22:29:06.327777: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c82f00 of size 256 next 54\n",
      "2023-07-28 22:29:06.327782: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83000 of size 256 next 67\n",
      "2023-07-28 22:29:06.327786: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83100 of size 256 next 60\n",
      "2023-07-28 22:29:06.327792: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83200 of size 256 next 71\n",
      "2023-07-28 22:29:06.327796: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83300 of size 256 next 51\n",
      "2023-07-28 22:29:06.327801: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83400 of size 256 next 61\n",
      "2023-07-28 22:29:06.327806: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83500 of size 256 next 76\n",
      "2023-07-28 22:29:06.327811: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83600 of size 256 next 78\n",
      "2023-07-28 22:29:06.327815: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83700 of size 256 next 79\n",
      "2023-07-28 22:29:06.327820: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83800 of size 256 next 82\n",
      "2023-07-28 22:29:06.327825: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83900 of size 256 next 84\n",
      "2023-07-28 22:29:06.327829: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83a00 of size 256 next 80\n",
      "2023-07-28 22:29:06.327834: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83b00 of size 256 next 85\n",
      "2023-07-28 22:29:06.327839: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83c00 of size 256 next 101\n",
      "2023-07-28 22:29:06.327843: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83d00 of size 256 next 96\n",
      "2023-07-28 22:29:06.327848: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83e00 of size 256 next 93\n",
      "2023-07-28 22:29:06.327853: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83f00 of size 256 next 99\n",
      "2023-07-28 22:29:06.327858: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c84000 of size 256 next 53\n",
      "2023-07-28 22:29:06.327862: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c84100 of size 256 next 91\n",
      "2023-07-28 22:29:06.327867: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c84200 of size 256 next 86\n",
      "2023-07-28 22:29:06.327872: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c84300 of size 256 next 83\n",
      "2023-07-28 22:29:06.327876: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c84400 of size 256 next 52\n",
      "2023-07-28 22:29:06.327881: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c84500 of size 256 next 73\n",
      "2023-07-28 22:29:06.327886: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c84600 of size 148736 next 57\n",
      "2023-07-28 22:29:06.327892: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046ca8b00 of size 256 next 58\n",
      "2023-07-28 22:29:06.327896: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046ca8c00 of size 73728 next 46\n",
      "2023-07-28 22:29:06.327901: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046cbac00 of size 73728 next 74\n",
      "2023-07-28 22:29:06.327906: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046cccc00 of size 1024 next 64\n",
      "2023-07-28 22:29:06.327911: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046ccd000 of size 1024 next 69\n",
      "2023-07-28 22:29:06.327915: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046ccd400 of size 73728 next 65\n",
      "2023-07-28 22:29:06.327920: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046cdf400 of size 147456 next 44\n",
      "2023-07-28 22:29:06.327925: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046d03400 of size 147456 next 87\n",
      "2023-07-28 22:29:06.327930: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046d27400 of size 73728 next 105\n",
      "2023-07-28 22:29:06.327935: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046d39400 of size 147456 next 97\n",
      "2023-07-28 22:29:06.327940: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046d5d400 of size 221184 next 124\n",
      "2023-07-28 22:29:06.327945: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046d93400 of size 73728 next 129\n",
      "2023-07-28 22:29:06.327949: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046da5400 of size 73728 next 143\n",
      "2023-07-28 22:29:06.327953: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046db7400 of size 73728 next 142\n",
      "2023-07-28 22:29:06.327957: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046dc9400 of size 224256 next 18446744073709551615\n",
      "2023-07-28 22:29:06.327961: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-07-28 22:29:06.327966: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 103 Chunks of size 256 totalling 25.8KiB\n",
      "2023-07-28 22:29:06.327972: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 8 Chunks of size 1024 totalling 8.0KiB\n",
      "2023-07-28 22:29:06.327976: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-07-28 22:29:06.327981: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 9 Chunks of size 3584 totalling 31.5KiB\n",
      "2023-07-28 22:29:06.327985: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 9 Chunks of size 73728 totalling 648.0KiB\n",
      "2023-07-28 22:29:06.327990: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 7 Chunks of size 147456 totalling 1008.0KiB\n",
      "2023-07-28 22:29:06.327994: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 148736 totalling 145.2KiB\n",
      "2023-07-28 22:29:06.327999: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 221184 totalling 216.0KiB\n",
      "2023-07-28 22:29:06.328003: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 224256 totalling 219.0KiB\n",
      "2023-07-28 22:29:06.328008: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 796262400 totalling 759.38MiB\n",
      "2023-07-28 22:29:06.328013: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 7 Chunks of size 2074476544 totalling 13.52GiB\n",
      "2023-07-28 22:29:06.328017: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2117226496 totalling 1.97GiB\n",
      "2023-07-28 22:29:06.328021: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 2147483648 totalling 4.00GiB\n",
      "2023-07-28 22:29:06.328026: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2234564608 totalling 2.08GiB\n",
      "2023-07-28 22:29:06.328030: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 4209942528 totalling 3.92GiB\n",
      "2023-07-28 22:29:06.328034: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 8468905984 totalling 7.89GiB\n",
      "2023-07-28 22:29:06.328038: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 34.13GiB\n",
      "2023-07-28 22:29:06.328042: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 48732307456 memory_limit_: 48732307456 available bytes: 0 curr_region_allocation_bytes_: 68719476736\n",
      "2023-07-28 22:29:06.328051: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                     48732307456\n",
      "InUse:                     36645563136\n",
      "MaxInUse:                  40837136384\n",
      "NumAllocs:                       93278\n",
      "MaxAllocSize:               8589934592\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-07-28 22:29:06.328061: W tensorflow/tsl/framework/bfc_allocator.cc:492] _********************___******___******_______*****__*********__************************************\n",
      "2023-07-28 22:29:06.328089: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at bias_op.cc:419 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[2048,513909] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2023-07-28 22:29:06.328193: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.89GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-28 22:29:16.328602: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.89GiB (rounded to 8468905984)requested by op training_2/Adam/gradients/gradients/max_pooling2d_2/MaxPool_grad/MaxPoolGrad\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-07-28 22:29:16.328648: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-07-28 22:29:16.328663: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 102, Chunks in use: 101. 25.5KiB allocated for chunks. 25.2KiB in use in bin. 7.9KiB client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328672: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 1, Chunks in use: 0. 768B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328681: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 10, Chunks in use: 9. 10.2KiB allocated for chunks. 9.2KiB in use in bin. 9.0KiB client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328688: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 9, Chunks in use: 9. 31.5KiB allocated for chunks. 31.5KiB in use in bin. 30.4KiB client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328694: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328700: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328706: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 1, Chunks in use: 0. 31.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328712: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328719: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 10, Chunks in use: 10. 720.0KiB allocated for chunks. 720.0KiB in use in bin. 720.0KiB client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328726: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 10, Chunks in use: 9. 1.55MiB allocated for chunks. 1.41MiB in use in bin. 1.27MiB client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328732: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328737: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328743: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328749: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328754: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328760: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328765: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328771: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328777: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328783: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 138.90MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328794: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 19, Chunks in use: 13. 45.25GiB allocated for chunks. 30.21GiB in use in bin. 29.96GiB client-requested in use in bin.\n",
      "2023-07-28 22:29:16.328801: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 7.89GiB was 256.00MiB, Chunk State: \n",
      "2023-07-28 22:29:16.328814: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 278.50MiB | Requested Size: 759.38MiB | in_use: 0 | bin_num: 20, prev:   Size: 1.93GiB | Requested Size: 1.93GiB | in_use: 1 | bin_num: -1\n",
      "2023-07-28 22:29:16.328822: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 759.38MiB | Requested Size: 759.38MiB | in_use: 0 | bin_num: 20, next:   Size: 759.38MiB | Requested Size: 759.38MiB | in_use: 1 | bin_num: -1\n",
      "2023-07-28 22:29:16.328831: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 1.93GiB | Requested Size: 1000.81MiB | in_use: 0 | bin_num: 20, prev:   Size: 7.89GiB | Requested Size: 7.89GiB | in_use: 1 | bin_num: -1, next:   Size: 2.08GiB | Requested Size: 1.97GiB | in_use: 1 | bin_num: -1\n",
      "2023-07-28 22:29:16.328839: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 1.97GiB | Requested Size: 1.97GiB | in_use: 0 | bin_num: 20, next:   Size: 1.97GiB | Requested Size: 1.97GiB | in_use: 1 | bin_num: -1\n",
      "2023-07-28 22:29:16.328847: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 3.85GiB | Requested Size: 1000.81MiB | in_use: 0 | bin_num: 20, prev:   Size: 1.97GiB | Requested Size: 1.97GiB | in_use: 1 | bin_num: -1, next:   Size: 1.93GiB | Requested Size: 1.93GiB | in_use: 1 | bin_num: -1\n",
      "2023-07-28 22:29:16.328855: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 6.27GiB | Requested Size: 1000.81MiB | in_use: 0 | bin_num: 20, prev:   Size: 1.93GiB | Requested Size: 1.93GiB | in_use: 1 | bin_num: -1\n",
      "2023-07-28 22:29:16.328859: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 14370471936\n",
      "2023-07-28 22:29:16.328866: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f0074000000 of size 796262400 next 116\n",
      "2023-07-28 22:29:16.328873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f00a3760000 of size 796262400 next 122\n",
      "2023-07-28 22:29:16.328878: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f00d2ec0000 of size 8468905984 next 147\n",
      "2023-07-28 22:29:16.328885: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f02cbb54000 of size 2074476544 next 149\n",
      "2023-07-28 22:29:16.328891: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f03475b4000 of size 2234564608 next 18446744073709551615\n",
      "2023-07-28 22:29:16.328896: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 17179869184\n",
      "2023-07-28 22:29:16.328901: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f040c000000 of size 2117226496 next 157\n",
      "2023-07-28 22:29:16.328906: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f048a325000 of size 2117226496 next 146\n",
      "2023-07-28 22:29:16.328910: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f050864a000 of size 4136632320 next 148\n",
      "2023-07-28 22:29:16.328915: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f05fef4a000 of size 2074476544 next 162\n",
      "2023-07-28 22:29:16.328920: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f067a9aa000 of size 6734307328 next 18446744073709551615\n",
      "2023-07-28 22:29:16.328925: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 8589934592\n",
      "2023-07-28 22:29:16.328930: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f08f2000000 of size 2074476544 next 100\n",
      "2023-07-28 22:29:16.328935: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f096da60000 of size 2074476544 next 45\n",
      "2023-07-28 22:29:16.328939: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f09e94c0000 of size 2074476544 next 125\n",
      "2023-07-28 22:29:16.328944: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f0a64f20000 of size 2074476544 next 120\n",
      "2023-07-28 22:29:16.328950: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f0ae0980000 of size 292028416 next 18446744073709551615\n",
      "2023-07-28 22:29:16.328954: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 4294967296\n",
      "2023-07-28 22:29:16.328959: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f0afc000000 of size 2074476544 next 47\n",
      "2023-07-28 22:29:16.328964: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f0b77a60000 of size 2074476544 next 77\n",
      "2023-07-28 22:29:16.328969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f0bf34c0000 of size 147456 next 152\n",
      "2023-07-28 22:29:16.328974: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f0bf34e4000 of size 147456 next 166\n",
      "2023-07-28 22:29:16.328979: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f0bf3508000 of size 73728 next 163\n",
      "2023-07-28 22:29:16.328983: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f0bf351a000 of size 145645568 next 18446744073709551615\n",
      "2023-07-28 22:29:16.328988: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 2147483648\n",
      "2023-07-28 22:29:16.328993: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f0c30000000 of size 2147483648 next 18446744073709551615\n",
      "2023-07-28 22:29:16.328998: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 2147483648\n",
      "2023-07-28 22:29:16.329002: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f0cb6000000 of size 2147483648 next 18446744073709551615\n",
      "2023-07-28 22:29:16.329007: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 2097152\n",
      "2023-07-28 22:29:16.329012: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00000 of size 1280 next 1\n",
      "2023-07-28 22:29:16.329017: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00500 of size 256 next 2\n",
      "2023-07-28 22:29:16.329023: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00600 of size 256 next 3\n",
      "2023-07-28 22:29:16.329027: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00700 of size 256 next 4\n",
      "2023-07-28 22:29:16.329032: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00800 of size 256 next 5\n",
      "2023-07-28 22:29:16.329037: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00900 of size 256 next 6\n",
      "2023-07-28 22:29:16.329041: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00a00 of size 256 next 7\n",
      "2023-07-28 22:29:16.329046: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00b00 of size 256 next 8\n",
      "2023-07-28 22:29:16.329051: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00c00 of size 256 next 9\n",
      "2023-07-28 22:29:16.329055: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00d00 of size 256 next 10\n",
      "2023-07-28 22:29:16.329060: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00e00 of size 256 next 11\n",
      "2023-07-28 22:29:16.329065: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c00f00 of size 256 next 12\n",
      "2023-07-28 22:29:16.329069: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c01000 of size 256 next 13\n",
      "2023-07-28 22:29:16.329074: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c01100 of size 256 next 14\n",
      "2023-07-28 22:29:16.329079: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c01200 of size 3584 next 15\n",
      "2023-07-28 22:29:16.329084: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c02000 of size 256 next 16\n",
      "2023-07-28 22:29:16.329089: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c02100 of size 73728 next 17\n",
      "2023-07-28 22:29:16.329093: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c14100 of size 256 next 18\n",
      "2023-07-28 22:29:16.329098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c14200 of size 147456 next 19\n",
      "2023-07-28 22:29:16.329103: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c38200 of size 256 next 20\n",
      "2023-07-28 22:29:16.329108: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c38300 of size 256 next 21\n",
      "2023-07-28 22:29:16.329112: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c38400 of size 256 next 23\n",
      "2023-07-28 22:29:16.329117: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c38500 of size 1024 next 24\n",
      "2023-07-28 22:29:16.329122: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c38900 of size 256 next 25\n",
      "2023-07-28 22:29:16.329127: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c38a00 of size 256 next 26\n",
      "2023-07-28 22:29:16.329131: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c38b00 of size 147456 next 27\n",
      "2023-07-28 22:29:16.329136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c5cb00 of size 73728 next 28\n",
      "2023-07-28 22:29:16.329141: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c6eb00 of size 3584 next 30\n",
      "2023-07-28 22:29:16.329145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c6f900 of size 1024 next 31\n",
      "2023-07-28 22:29:16.329150: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c6fd00 of size 256 next 32\n",
      "2023-07-28 22:29:16.329155: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c6fe00 of size 256 next 33\n",
      "2023-07-28 22:29:16.329159: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c6ff00 of size 256 next 34\n",
      "2023-07-28 22:29:16.329164: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70000 of size 256 next 35\n",
      "2023-07-28 22:29:16.329169: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70100 of size 256 next 36\n",
      "2023-07-28 22:29:16.329173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70200 of size 256 next 37\n",
      "2023-07-28 22:29:16.329178: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70300 of size 256 next 38\n",
      "2023-07-28 22:29:16.329183: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70400 of size 256 next 39\n",
      "2023-07-28 22:29:16.329187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70500 of size 256 next 40\n",
      "2023-07-28 22:29:16.329192: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70600 of size 256 next 41\n",
      "2023-07-28 22:29:16.329197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70700 of size 256 next 70\n",
      "2023-07-28 22:29:16.329201: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70800 of size 256 next 42\n",
      "2023-07-28 22:29:16.329206: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70900 of size 256 next 88\n",
      "2023-07-28 22:29:16.329211: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70a00 of size 256 next 55\n",
      "2023-07-28 22:29:16.329215: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70b00 of size 256 next 68\n",
      "2023-07-28 22:29:16.329220: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c70c00 of size 3584 next 56\n",
      "2023-07-28 22:29:16.329225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c71a00 of size 3584 next 49\n",
      "2023-07-28 22:29:16.329229: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c72800 of size 3584 next 104\n",
      "2023-07-28 22:29:16.329234: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c73600 of size 256 next 90\n",
      "2023-07-28 22:29:16.329239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c73700 of size 1024 next 102\n",
      "2023-07-28 22:29:16.329243: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c73b00 of size 256 next 92\n",
      "2023-07-28 22:29:16.329248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c73c00 of size 256 next 89\n",
      "2023-07-28 22:29:16.329253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c73d00 of size 1024 next 81\n",
      "2023-07-28 22:29:16.329257: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c74100 of size 3584 next 95\n",
      "2023-07-28 22:29:16.329262: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c74f00 of size 256 next 103\n",
      "2023-07-28 22:29:16.329268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75000 of size 256 next 94\n",
      "2023-07-28 22:29:16.329273: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75100 of size 256 next 98\n",
      "2023-07-28 22:29:16.329277: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75200 of size 256 next 106\n",
      "2023-07-28 22:29:16.329282: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75300 of size 256 next 107\n",
      "2023-07-28 22:29:16.329287: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75400 of size 256 next 108\n",
      "2023-07-28 22:29:16.329291: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75500 of size 256 next 109\n",
      "2023-07-28 22:29:16.329296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75600 of size 256 next 110\n",
      "2023-07-28 22:29:16.329301: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75700 of size 256 next 111\n",
      "2023-07-28 22:29:16.329305: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75800 of size 256 next 112\n",
      "2023-07-28 22:29:16.329310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75900 of size 256 next 133\n",
      "2023-07-28 22:29:16.329315: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75a00 of size 256 next 139\n",
      "2023-07-28 22:29:16.329319: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75b00 of size 256 next 115\n",
      "2023-07-28 22:29:16.329324: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75c00 of size 256 next 135\n",
      "2023-07-28 22:29:16.329329: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75d00 of size 256 next 136\n",
      "2023-07-28 22:29:16.329333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c75e00 of size 256 next 145\n",
      "2023-07-28 22:29:16.329338: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1046c75f00 of size 1024 next 154\n",
      "2023-07-28 22:29:16.329343: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76300 of size 256 next 155\n",
      "2023-07-28 22:29:16.329348: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1046c76400 of size 256 next 161\n",
      "2023-07-28 22:29:16.329352: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76500 of size 256 next 167\n",
      "2023-07-28 22:29:16.329357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76600 of size 256 next 150\n",
      "2023-07-28 22:29:16.329362: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76700 of size 256 next 158\n",
      "2023-07-28 22:29:16.329366: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1046c76800 of size 768 next 117\n",
      "2023-07-28 22:29:16.329371: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76b00 of size 256 next 118\n",
      "2023-07-28 22:29:16.329376: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76c00 of size 256 next 126\n",
      "2023-07-28 22:29:16.329380: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76d00 of size 256 next 113\n",
      "2023-07-28 22:29:16.329385: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76e00 of size 256 next 123\n",
      "2023-07-28 22:29:16.329390: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c76f00 of size 256 next 134\n",
      "2023-07-28 22:29:16.329394: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77000 of size 256 next 159\n",
      "2023-07-28 22:29:16.329399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77100 of size 256 next 160\n",
      "2023-07-28 22:29:16.329404: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77200 of size 256 next 121\n",
      "2023-07-28 22:29:16.329408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77300 of size 256 next 114\n",
      "2023-07-28 22:29:16.329413: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77400 of size 256 next 131\n",
      "2023-07-28 22:29:16.329417: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77500 of size 256 next 137\n",
      "2023-07-28 22:29:16.329422: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77600 of size 256 next 140\n",
      "2023-07-28 22:29:16.329427: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77700 of size 256 next 141\n",
      "2023-07-28 22:29:16.329431: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77800 of size 256 next 130\n",
      "2023-07-28 22:29:16.329436: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77900 of size 1024 next 127\n",
      "2023-07-28 22:29:16.329441: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77d00 of size 256 next 128\n",
      "2023-07-28 22:29:16.329446: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c77e00 of size 1024 next 132\n",
      "2023-07-28 22:29:16.329450: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c78200 of size 3584 next 144\n",
      "2023-07-28 22:29:16.329455: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c79000 of size 3584 next 119\n",
      "2023-07-28 22:29:16.329460: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c79e00 of size 3584 next 138\n",
      "2023-07-28 22:29:16.329464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1046c7ac00 of size 32512 next 63\n",
      "2023-07-28 22:29:16.329469: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c82b00 of size 256 next 72\n",
      "2023-07-28 22:29:16.329474: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c82c00 of size 256 next 62\n",
      "2023-07-28 22:29:16.329478: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c82d00 of size 256 next 66\n",
      "2023-07-28 22:29:16.329483: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c82e00 of size 256 next 50\n",
      "2023-07-28 22:29:16.329488: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c82f00 of size 256 next 54\n",
      "2023-07-28 22:29:16.329492: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83000 of size 256 next 67\n",
      "2023-07-28 22:29:16.329497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83100 of size 256 next 60\n",
      "2023-07-28 22:29:16.329502: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83200 of size 256 next 71\n",
      "2023-07-28 22:29:16.329506: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83300 of size 256 next 51\n",
      "2023-07-28 22:29:16.329511: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83400 of size 256 next 61\n",
      "2023-07-28 22:29:16.329516: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83500 of size 256 next 76\n",
      "2023-07-28 22:29:16.329520: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83600 of size 256 next 78\n",
      "2023-07-28 22:29:16.329525: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83700 of size 256 next 79\n",
      "2023-07-28 22:29:16.329530: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83800 of size 256 next 82\n",
      "2023-07-28 22:29:16.329534: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83900 of size 256 next 84\n",
      "2023-07-28 22:29:16.329539: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83a00 of size 256 next 80\n",
      "2023-07-28 22:29:16.329544: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83b00 of size 256 next 85\n",
      "2023-07-28 22:29:16.329548: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83c00 of size 256 next 101\n",
      "2023-07-28 22:29:16.329553: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83d00 of size 256 next 96\n",
      "2023-07-28 22:29:16.329558: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83e00 of size 256 next 93\n",
      "2023-07-28 22:29:16.329562: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c83f00 of size 256 next 99\n",
      "2023-07-28 22:29:16.329567: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c84000 of size 256 next 53\n",
      "2023-07-28 22:29:16.329572: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c84100 of size 256 next 91\n",
      "2023-07-28 22:29:16.329577: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c84200 of size 256 next 86\n",
      "2023-07-28 22:29:16.329581: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c84300 of size 256 next 83\n",
      "2023-07-28 22:29:16.329586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c84400 of size 256 next 52\n",
      "2023-07-28 22:29:16.329591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c84500 of size 256 next 73\n",
      "2023-07-28 22:29:16.329595: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046c84600 of size 148736 next 57\n",
      "2023-07-28 22:29:16.329600: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046ca8b00 of size 256 next 58\n",
      "2023-07-28 22:29:16.329605: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046ca8c00 of size 73728 next 46\n",
      "2023-07-28 22:29:16.329610: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046cbac00 of size 73728 next 74\n",
      "2023-07-28 22:29:16.329614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046cccc00 of size 1024 next 64\n",
      "2023-07-28 22:29:16.329619: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046ccd000 of size 1024 next 69\n",
      "2023-07-28 22:29:16.329624: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046ccd400 of size 73728 next 65\n",
      "2023-07-28 22:29:16.329629: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046cdf400 of size 147456 next 44\n",
      "2023-07-28 22:29:16.329633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046d03400 of size 147456 next 87\n",
      "2023-07-28 22:29:16.329638: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046d27400 of size 73728 next 105\n",
      "2023-07-28 22:29:16.329643: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046d39400 of size 147456 next 97\n",
      "2023-07-28 22:29:16.329648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046d5d400 of size 221184 next 124\n",
      "2023-07-28 22:29:16.329652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046d93400 of size 73728 next 129\n",
      "2023-07-28 22:29:16.329657: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046da5400 of size 73728 next 143\n",
      "2023-07-28 22:29:16.329662: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046db7400 of size 73728 next 142\n",
      "2023-07-28 22:29:16.329667: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1046dc9400 of size 224256 next 18446744073709551615\n",
      "2023-07-28 22:29:16.329671: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-07-28 22:29:16.329678: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 101 Chunks of size 256 totalling 25.2KiB\n",
      "2023-07-28 22:29:16.329685: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 8 Chunks of size 1024 totalling 8.0KiB\n",
      "2023-07-28 22:29:16.329691: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-07-28 22:29:16.329696: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 9 Chunks of size 3584 totalling 31.5KiB\n",
      "2023-07-28 22:29:16.329702: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 10 Chunks of size 73728 totalling 720.0KiB\n",
      "2023-07-28 22:29:16.329708: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 147456 totalling 864.0KiB\n",
      "2023-07-28 22:29:16.329713: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 148736 totalling 145.2KiB\n",
      "2023-07-28 22:29:16.329719: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 221184 totalling 216.0KiB\n",
      "2023-07-28 22:29:16.329725: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 224256 totalling 219.0KiB\n",
      "2023-07-28 22:29:16.329730: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 796262400 totalling 759.38MiB\n",
      "2023-07-28 22:29:16.329736: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 7 Chunks of size 2074476544 totalling 13.52GiB\n",
      "2023-07-28 22:29:16.329741: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2117226496 totalling 1.97GiB\n",
      "2023-07-28 22:29:16.329747: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 2147483648 totalling 4.00GiB\n",
      "2023-07-28 22:29:16.329752: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2234564608 totalling 2.08GiB\n",
      "2023-07-28 22:29:16.329758: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 8468905984 totalling 7.89GiB\n",
      "2023-07-28 22:29:16.329763: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 30.21GiB\n",
      "2023-07-28 22:29:16.329768: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 48732307456 memory_limit_: 48732307456 available bytes: 0 curr_region_allocation_bytes_: 68719476736\n",
      "2023-07-28 22:29:16.329778: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                     48732307456\n",
      "InUse:                     32435546368\n",
      "MaxInUse:                  40837136384\n",
      "NumAllocs:                       93283\n",
      "MaxAllocSize:               8589934592\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-07-28 22:29:16.329790: W tensorflow/tsl/framework/bfc_allocator.cc:492] _********************___******___******_______*****_____________************************************\n",
      "2023-07-28 22:29:16.329818: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at pooling_ops_common.cc:453 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,32,1078,1918] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2048,513909] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_2/Adam/gradients/gradients/conv2d_4/BiasAdd_grad/BiasAddGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4109976/375847468.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Train the model with the checkpoint callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m         return func.fit(\n\u001b[0m\u001b[1;32m    855\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         return fit_loop(\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4579\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4581\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4582\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4583\u001b[0m         output_structure = tf.nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1482\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2048,513909] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_2/Adam/gradients/gradients/conv2d_4/BiasAdd_grad/BiasAddGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(1080, 1920, 3), kernel_regularizer=tf.keras.regularizers.l2(0.001))) #(1080, 1920, 3) #(1080, 1350, 3)\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(Dense(4))  # Output layer with 4 units for regression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "def checkpoint_name(epoch, logs):\n",
    "    return os.path.join(checkpoint_dir, f\"weights_epoch_{epoch:02d}.h5\")\n",
    "# def checkpoint_name(epoch):\n",
    "#     return os.path.join(checkpoint_dir, f\"weights_epoch_{epoch}.h5\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath= checkpoint_name,\n",
    "    save_weights_only=True,    # save weights only, not the entire model\n",
    "    period=1  # Save every 10 epochs\n",
    ")\n",
    "\n",
    "# Train the model with the checkpoint callback\n",
    "history = model.fit(X_train1, Y_train, epochs=50, batch_size=32, callbacks=[checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"path_to_your_saved_weights.h5\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8692 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 13:22:15.610083: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-07-25 13:22:15.736265: W tensorflow/c/c_api.cc:291] Operation '{name:'training/Adam/dense_1/kernel/v/Assign' id:408 op device:{requested: '', assigned: ''} def:{{{node training/Adam/dense_1/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/dense_1/kernel/v, training/Adam/dense_1/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-07-25 13:22:18.084351: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2023-07-25 13:22:18.593045: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700\n",
      "2023-07-25 13:22:20.196391: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 286s 33ms/sample - loss: 785.0329\n",
      "Epoch 2/50\n",
      "8692/8692 [==============================] - 274s 32ms/sample - loss: 25.6952\n",
      "Epoch 3/50\n",
      "8692/8692 [==============================] - 275s 32ms/sample - loss: 24.4339\n",
      "Epoch 4/50\n",
      "8692/8692 [==============================] - 275s 32ms/sample - loss: 23.9605\n",
      "Epoch 5/50\n",
      "8692/8692 [==============================] - 271s 31ms/sample - loss: 22.5596\n",
      "Epoch 6/50\n",
      "8692/8692 [==============================] - 272s 31ms/sample - loss: 22.7819\n",
      "Epoch 7/50\n",
      "8692/8692 [==============================] - 273s 31ms/sample - loss: 22.0148\n",
      "Epoch 8/50\n",
      "8692/8692 [==============================] - 272s 31ms/sample - loss: 20.0527\n",
      "Epoch 9/50\n",
      "8692/8692 [==============================] - 273s 31ms/sample - loss: 19.0347\n",
      "Epoch 10/50\n",
      "8692/8692 [==============================] - 273s 31ms/sample - loss: 18.8331\n",
      "Epoch 11/50\n",
      "8692/8692 [==============================] - 273s 31ms/sample - loss: 17.6107\n",
      "Epoch 12/50\n",
      "8692/8692 [==============================] - 277s 32ms/sample - loss: 17.2632\n",
      "Epoch 13/50\n",
      "8692/8692 [==============================] - 277s 32ms/sample - loss: 17.3518\n",
      "Epoch 14/50\n",
      "8692/8692 [==============================] - 279s 32ms/sample - loss: 16.8014\n",
      "Epoch 15/50\n",
      "8692/8692 [==============================] - 280s 32ms/sample - loss: 16.3485\n",
      "Epoch 16/50\n",
      "8692/8692 [==============================] - 284s 33ms/sample - loss: 15.3259\n",
      "Epoch 17/50\n",
      "8692/8692 [==============================] - 287s 33ms/sample - loss: 14.9019\n",
      "Epoch 18/50\n",
      "8692/8692 [==============================] - 285s 33ms/sample - loss: 14.1981\n",
      "Epoch 19/50\n",
      "8692/8692 [==============================] - 287s 33ms/sample - loss: 13.1824\n",
      "Epoch 20/50\n",
      "8692/8692 [==============================] - 286s 33ms/sample - loss: 12.2337\n",
      "Epoch 21/50\n",
      "8692/8692 [==============================] - 292s 34ms/sample - loss: 10.7562\n",
      "Epoch 22/50\n",
      "8692/8692 [==============================] - 292s 34ms/sample - loss: 9.2852\n",
      "Epoch 23/50\n",
      "8692/8692 [==============================] - 293s 34ms/sample - loss: 8.4040\n",
      "Epoch 24/50\n",
      "8692/8692 [==============================] - 293s 34ms/sample - loss: 7.7294\n",
      "Epoch 25/50\n",
      "8692/8692 [==============================] - 293s 34ms/sample - loss: 7.4109\n",
      "Epoch 26/50\n",
      "8692/8692 [==============================] - 293s 34ms/sample - loss: 7.3383\n",
      "Epoch 27/50\n",
      "8692/8692 [==============================] - 293s 34ms/sample - loss: 6.9887\n",
      "Epoch 28/50\n",
      "8692/8692 [==============================] - 292s 34ms/sample - loss: 6.7099\n",
      "Epoch 29/50\n",
      "8692/8692 [==============================] - 292s 34ms/sample - loss: 6.5987\n",
      "Epoch 30/50\n",
      "8692/8692 [==============================] - 289s 33ms/sample - loss: 6.4631\n",
      "Epoch 31/50\n",
      " 448/8692 [>.............................] - ETA: 4:34 - loss: 4.9975"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(1080, 1920, 3), kernel_regularizer=tf.keras.regularizers.l2(0.001))) #(1080, 1920, 3) #(1080, 1350, 3)\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(Dense(4))  # Output layer with 3 units for regression\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train1, Y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(1080, 1920, 3), kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(MaxPooling2D((2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(MaxPooling2D((2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Dense(3))  # Output layer with 3 units for regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=optimizer, loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"contact_noncontact_model_50ep.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 25 02:28:07 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX 6000...  On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 42%   66C    P2    84W / 300W |  47843MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX 6000...  On   | 00000000:61:00.0 Off |                  Off |\n",
      "| 30%   32C    P8    26W / 300W |    639MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   3185942      C   /bin/python3                    47832MiB |\n",
      "|    1   N/A  N/A   3185942      C   /bin/python3                      628MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain the loss values from the training history\n",
    "loss_values = history.history['loss']\n",
    "\n",
    "# Plot the loss graph\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'b', label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "# plt.xlim(0, len(loss_values) + 1)\n",
    "# plt.ylim(0, max(loss_values) + 100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain the loss values from the training history\n",
    "loss_values = history.history['loss']\n",
    "\n",
    "# Plot the loss graph\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'b', label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "# plt.xlim(0, len(loss_values) + 1)\n",
    "# plt.ylim(0, max(loss_values) + 100)\n",
    "plt.ylim(0, 30)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-07-25 02:28:08.446114: W tensorflow/c/c_api.cc:291] Operation '{name:'dense_1/BiasAdd' id:110 op device:{requested: '', assigned: ''} def:{{{node dense_1/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_1/MatMul, dense_1/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 16.439082820995\n",
      "Root Mean Squared Error (RMSE): 4.05451388220524\n",
      "Mean Absolute Error (MAE): 1.9492433203539943\n",
      "R-squared (R2): 0.3702791126089917\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "\n",
    "Y_pred = model.predict(X_test1)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print('Mean Squared Error (MSE):', mse)\n",
    "print('Root Mean Squared Error (RMSE):', rmse)\n",
    "print('Mean Absolute Error (MAE):', mae)\n",
    "print('R-squared (R2):', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[  1.4242349 -22.93267     0.7981034   1.1876472]]\n"
     ]
    }
   ],
   "source": [
    "sample_index = 6  # Replace with the index of the desired sample\n",
    "\n",
    "sample = np.expand_dims(X_test1[sample_index], axis=0) \n",
    "\n",
    "y_pred = model.predict(sample)\n",
    "\n",
    "print('Prediction:', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.33842565 -22.12015385   1.           1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[-13.584453   -28.08273      0.31239802   0.67342305]]\n"
     ]
    }
   ],
   "source": [
    "sample_index = 15  # Replace with the index of the desired sample\n",
    "\n",
    "sample = np.expand_dims(X_test1[sample_index], axis=0) \n",
    "\n",
    "y_pred = model.predict(sample)\n",
    "\n",
    "print('Prediction:', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-16.88556385 -25.87927952   0.           1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[ -1.052757  -33.802345    0.5072885   0.6418066]]\n"
     ]
    }
   ],
   "source": [
    "sample_index = 32  # Replace with the index of the desired sample\n",
    "\n",
    "sample = np.expand_dims(X_test1[sample_index], axis=0) \n",
    "\n",
    "y_pred = model.predict(sample)\n",
    "\n",
    "print('Prediction:', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.17081855 -30.74475237   0.           0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 28 10:38:01 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX 6000...  On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 55%   77C    P2   270W / 300W |  40369MiB / 49140MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX 6000...  On   | 00000000:61:00.0 Off |                  Off |\n",
      "| 30%   32C    P8    25W / 300W |      3MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   3950446      C   python3                         40366MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
