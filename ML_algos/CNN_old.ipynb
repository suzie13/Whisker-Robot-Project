{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "# import cv2\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"data_collection.csv\"\n",
    "columns = ['Serial_no','Timestamp', 'x_actual', 'y_actual', 'direction', 'x_step', 'y_step']\n",
    "data_df = pd.read_csv(csv_file, header=None, names = columns)\n",
    "\n",
    "serial_numbers = data_df['Serial_no'].astype(str).apply(lambda x: int(x.split(',')[0]))\n",
    "\n",
    "image_folder = \"output_images_new\"#\"cropped_noedges_new\" #\"output_images_new\" #\"images_resized_500\"\n",
    "imagess = []\n",
    "parsed_custom_info = []\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "data_df['direction'] = le.fit_transform(data_df['direction'])\n",
    "\n",
    "# for index, info in enumerate(data_df[0]):\n",
    "\n",
    "\n",
    "\n",
    "# serial_number = data_df['Serial_no.']\n",
    "serial_numbers = set(data_df['Serial_no'])\n",
    "\n",
    "date_time = data_df['Timestamp']\n",
    "x_coordinate = data_df['x_actual']\n",
    "y_coordinate = data_df['y_actual']\n",
    "direction = data_df['direction']\n",
    "x_step = data_df['x_step']\n",
    "y_step = data_df['y_step']\n",
    "\n",
    "data_df = data_df[3000:]\n",
    "\n",
    "image_files = os.listdir(image_folder)\n",
    "imagess = []\n",
    "\n",
    "for row in data_df.itertuples(index=False, name='data_df'):\n",
    "    serial_number = row.Serial_no\n",
    "    date_time = row.Timestamp\n",
    "    x_coordinate = row.x_actual\n",
    "    y_coordinate = row.y_actual\n",
    "    direction = row.direction\n",
    "    x_step = row.x_step\n",
    "    y_step = row.y_step\n",
    "\n",
    "    # if ~(pd.isna(x_coordinate) and pd.isna(y_coordinate)):\n",
    "    # if ~(pd.isnull(x_coordinate) and pd.isnull(y_coordinate)):\n",
    "    # if pd.notnull(x_coordinate) and pd.notnull(y_coordinate):\n",
    "    # if not math.isnan(x_coordinate) and not math.isnan(y_coordinate):\n",
    "    # if not x_coordinate.empty and not y_coordinate.empty:\n",
    "    # if not(direction == 0 and x_coordinate > 4.49) or not(direction == 1 and y_coordinate < -18.81):\n",
    "\n",
    "    #############################\n",
    "    if pd.notnull(x_coordinate) and pd.notnull(y_coordinate) and \\\n",
    "        not((direction == 0 and (x_coordinate > 4.49 or x_coordinate < -12.5)) \\\n",
    "               or (direction == 1 and (x_coordinate < -18.81 or x_coordinate > -3.075))):\n",
    "            matching_files = [filename for filename in image_files if filename.startswith(str(serial_number))]\n",
    "            if matching_files:\n",
    "                image_name = matching_files[0]  # Assuming there is only one matching file\n",
    "                image_path = os.path.join(image_folder, image_name)\n",
    "                image = cv2.imread(image_path)\n",
    "                # if image is not None: \n",
    "                imagess.append(image)\n",
    "                parsed_custom_info.append([x_coordinate, y_coordinate, direction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_value = data_df['column_name'].max()\n",
    "\n",
    "# # Find the minimum value\n",
    "# min_value = data_df['column_name'].min()\n",
    "\n",
    "# print(\"Maximum value:\", max_value)\n",
    "# print(\"Minimum value:\", min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3930, 7)\n"
     ]
    }
   ],
   "source": [
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = data_df.groupby(['direction'])\n",
    "# df1 = grouped.get_group((0))\n",
    "# df2 = grouped.get_group((1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1960, 7)\n",
      "(1970, 7)\n"
     ]
    }
   ],
   "source": [
    "# print(df1.shape)\n",
    "# print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# print(data_df['direction'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 19 13:22:20 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX 6000...  On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 30%   38C    P8    21W / 300W |      1MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX 6000...  On   | 00000000:61:00.0 Off |                  Off |\n",
      "| 30%   50C    P3    58W / 300W |      1MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(imagess, parsed_custom_info))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend import set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 13:22:32.198062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 13:22:32.198264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 13:22:32.213465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 13:22:32.213711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 13:22:32.213870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 13:22:32.214023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 13:22:32.868208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 13:22:32.868409: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 13:22:32.868582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 13:22:32.868741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 13:22:32.868893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 13:22:32.869017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46476 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "2023-07-19 13:22:32.869410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 13:22:32.869527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 2181 MB memory:  -> device: 1, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:61:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "# config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split the dataset\n",
    "np.random.shuffle(data)\n",
    "train_ratio = 0.9\n",
    "train_size = int(len(data) * train_ratio)\n",
    "\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "X_train = [item[0] for item in train_data]\n",
    "Y_train = [item[1] for item in train_data]\n",
    "\n",
    "X_test = [item[0] for item in test_data]\n",
    "Y_test = [item[1] for item in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = np.array(X_test)\n",
    "X_train1 = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = X_test1.astype('float32')\n",
    "X_train1 = X_train1.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_nan = data_df['x_actual'].isnull().values.any()\n",
    "# print(check_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if np.isnan(parsed_custom_info).any():\n",
    "    # print(\"The array contains NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(parsed_custom_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Shape X_train: \", np.shape(X_train1))\n",
    "# print(\"Shape Y_train: \", np.shape(Y_train))\n",
    "\n",
    "# print(\"Shape X_test: \", np.shape(X_test1))\n",
    "# print(\"Shape Y_test: \", np.shape(Y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train = np.nan_to_num(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 862 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 13:23:11.091126: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-07-19 13:23:11.220320: W tensorflow/c/c_api.cc:291] Operation '{name:'training/Adam/conv2d/bias/v/Assign' id:367 op device:{requested: '', assigned: ''} def:{{{node training/Adam/conv2d/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/conv2d/bias/v, training/Adam/conv2d/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-07-19 13:23:13.945526: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2023-07-19 13:23:14.523340: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700\n",
      "2023-07-19 13:23:16.214161: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862/862 [==============================] - 47s 54ms/sample - loss: 9728.8331\n",
      "Epoch 2/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 27.5688\n",
      "Epoch 3/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 24.0417\n",
      "Epoch 4/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 20.9468\n",
      "Epoch 5/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 18.5101\n",
      "Epoch 6/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 18.8044\n",
      "Epoch 7/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 17.7995\n",
      "Epoch 8/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 20.1898\n",
      "Epoch 9/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 16.9516\n",
      "Epoch 10/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 18.6249\n",
      "Epoch 11/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 18.8403\n",
      "Epoch 12/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 15.3465\n",
      "Epoch 13/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 16.0433\n",
      "Epoch 14/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 26.3762\n",
      "Epoch 15/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 15.3942\n",
      "Epoch 16/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 14.6279\n",
      "Epoch 17/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 14.7336\n",
      "Epoch 18/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 15.6363\n",
      "Epoch 19/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 13.4606\n",
      "Epoch 20/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 13.8592\n",
      "Epoch 21/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 15.5833\n",
      "Epoch 22/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 13.3886\n",
      "Epoch 23/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 13.0322\n",
      "Epoch 24/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 12.6855\n",
      "Epoch 25/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 11.4378\n",
      "Epoch 26/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 11.2779\n",
      "Epoch 27/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 10.0041\n",
      "Epoch 28/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 10.4974\n",
      "Epoch 29/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 12.7870\n",
      "Epoch 30/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 10.4570\n",
      "Epoch 31/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 9.9508\n",
      "Epoch 32/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 8.9710\n",
      "Epoch 33/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 9.1891\n",
      "Epoch 34/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 7.7107\n",
      "Epoch 35/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 9.5041\n",
      "Epoch 36/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 7.6819\n",
      "Epoch 37/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 6.0406\n",
      "Epoch 38/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 6.9973\n",
      "Epoch 39/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 6.6436\n",
      "Epoch 40/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 4.8612\n",
      "Epoch 41/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 4.2755\n",
      "Epoch 42/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 3.3054\n",
      "Epoch 43/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 3.4816\n",
      "Epoch 44/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 3.2602\n",
      "Epoch 45/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 3.2969\n",
      "Epoch 46/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 3.4959\n",
      "Epoch 47/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 3.2025\n",
      "Epoch 48/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 3.8064\n",
      "Epoch 49/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 3.0595\n",
      "Epoch 50/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 2.7221\n",
      "Epoch 51/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 2.6670\n",
      "Epoch 52/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 3.0685\n",
      "Epoch 53/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 2.2927\n",
      "Epoch 54/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 2.6142\n",
      "Epoch 55/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 3.0705\n",
      "Epoch 56/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 3.0578\n",
      "Epoch 57/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 2.5844\n",
      "Epoch 58/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 2.7687\n",
      "Epoch 59/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 2.3369\n",
      "Epoch 60/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.8509\n",
      "Epoch 61/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 2.2572\n",
      "Epoch 62/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.7684\n",
      "Epoch 63/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.7330\n",
      "Epoch 64/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.6358\n",
      "Epoch 65/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 2.0714\n",
      "Epoch 66/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.7927\n",
      "Epoch 67/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.4130\n",
      "Epoch 68/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.7137\n",
      "Epoch 69/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.7877\n",
      "Epoch 70/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.3915\n",
      "Epoch 71/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.4109\n",
      "Epoch 72/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.7217\n",
      "Epoch 73/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.3216\n",
      "Epoch 74/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.2053\n",
      "Epoch 75/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.3960\n",
      "Epoch 76/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.3294\n",
      "Epoch 77/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.1428\n",
      "Epoch 78/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.4029\n",
      "Epoch 79/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.4250\n",
      "Epoch 80/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.3412\n",
      "Epoch 81/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.2858\n",
      "Epoch 82/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.2762\n",
      "Epoch 83/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.2494\n",
      "Epoch 84/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.4546\n",
      "Epoch 85/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.6339\n",
      "Epoch 86/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.0898\n",
      "Epoch 87/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.3250\n",
      "Epoch 88/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.1713\n",
      "Epoch 89/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.2803\n",
      "Epoch 90/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.2415\n",
      "Epoch 91/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.2463\n",
      "Epoch 92/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.5042\n",
      "Epoch 93/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.6428\n",
      "Epoch 94/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.7439\n",
      "Epoch 95/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.1759\n",
      "Epoch 96/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.0116\n",
      "Epoch 97/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.8496\n",
      "Epoch 98/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.0519\n",
      "Epoch 99/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.9521\n",
      "Epoch 100/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 0.8988\n",
      "Epoch 101/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.3171\n",
      "Epoch 102/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.3416\n",
      "Epoch 103/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.3155\n",
      "Epoch 104/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.7808\n",
      "Epoch 105/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.3740\n",
      "Epoch 106/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 2.0371\n",
      "Epoch 107/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.4585\n",
      "Epoch 108/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.0549\n",
      "Epoch 109/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.1996\n",
      "Epoch 110/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 0.9286\n",
      "Epoch 111/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.0148\n",
      "Epoch 112/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.9816\n",
      "Epoch 113/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.0068\n",
      "Epoch 114/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.2751\n",
      "Epoch 115/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.7537\n",
      "Epoch 116/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 0.7882\n",
      "Epoch 117/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.0481\n",
      "Epoch 118/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.8958\n",
      "Epoch 119/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.9205\n",
      "Epoch 120/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.9586\n",
      "Epoch 121/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.7198\n",
      "Epoch 122/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.8230\n",
      "Epoch 123/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.7198\n",
      "Epoch 124/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 0.8954\n",
      "Epoch 125/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 0.8855\n",
      "Epoch 126/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.8606\n",
      "Epoch 127/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 0.9195\n",
      "Epoch 128/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.2795\n",
      "Epoch 129/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.9740\n",
      "Epoch 130/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.0920\n",
      "Epoch 131/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.0247\n",
      "Epoch 132/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.9076\n",
      "Epoch 133/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.9317\n",
      "Epoch 134/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.9218\n",
      "Epoch 135/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.8004\n",
      "Epoch 136/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.0157\n",
      "Epoch 137/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.9515\n",
      "Epoch 138/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.3243\n",
      "Epoch 139/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.8537\n",
      "Epoch 140/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.1531\n",
      "Epoch 141/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 0.8958\n",
      "Epoch 142/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.3464\n",
      "Epoch 143/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.0153\n",
      "Epoch 144/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.0423\n",
      "Epoch 145/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 1.6436\n",
      "Epoch 146/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.9284\n",
      "Epoch 147/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.2217\n",
      "Epoch 148/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 1.0326\n",
      "Epoch 149/150\n",
      "862/862 [==============================] - 28s 33ms/sample - loss: 0.9107\n",
      "Epoch 150/150\n",
      "862/862 [==============================] - 29s 33ms/sample - loss: 0.6881\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(1080, 1920, 3), kernel_regularizer=tf.keras.regularizers.l2(0.001))) #(1080, 1920, 3) #(1080, 1350, 3)\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(Dense(3))  # Output layer with 3 units for regression\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history_left = model.fit(X_train1, Y_train, epochs=150, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(1080, 1920, 3), kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(MaxPooling2D((2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(MaxPooling2D((2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Dense(3))  # Output layer with 3 units for regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=optimizer, loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"removednoncontactdatacompletely_model_150ep.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 19 17:37:19 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX 6000...  On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 30%   38C    P8    21W / 300W |      1MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX 6000...  On   | 00000000:61:00.0 Off |                  Off |\n",
      "| 30%   33C    P8    25W / 300W |      1MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the loss values from the training history\n",
    "loss_values = history.history['loss']\n",
    "\n",
    "# Plot the loss graph\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'b', label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "# plt.xlim(0, len(loss_values) + 1)\n",
    "# plt.ylim(0, max(loss_values) + 100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the loss values from the training history\n",
    "loss_values = history.history['loss']\n",
    "\n",
    "# Plot the loss graph\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'b', label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "# plt.xlim(0, len(loss_values) + 1)\n",
    "# plt.ylim(0, max(loss_values) + 100)\n",
    "plt.ylim(0, 30)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-07-19 11:19:51.626281: W tensorflow/c/c_api.cc:291] Operation '{name:'dense_3/BiasAdd' id:271 op device:{requested: '', assigned: ''} def:{{{node dense_3/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_3/MatMul, dense_3/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 6.3553212282477745\n",
      "Root Mean Squared Error (RMSE): 2.52097624507804\n",
      "Mean Absolute Error (MAE): 1.296749566704765\n",
      "R-squared (R2): 0.6020065608068376\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "\n",
    "Y_pred = model.predict(X_test1)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print('Mean Squared Error (MSE):', mse)\n",
    "print('Root Mean Squared Error (RMSE):', rmse)\n",
    "print('Mean Absolute Error (MAE):', mae)\n",
    "print('R-squared (R2):', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 6  # Replace with the index of the desired sample\n",
    "\n",
    "sample = np.expand_dims(X_test1[sample_index], axis=0) \n",
    "\n",
    "y_pred = model.predict(sample)\n",
    "\n",
    "print('Prediction:', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_test[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 15  # Replace with the index of the desired sample\n",
    "\n",
    "sample = np.expand_dims(X_test1[sample_index], axis=0) \n",
    "\n",
    "y_pred = model.predict(sample)\n",
    "\n",
    "print('Prediction:', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_test[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 32  # Replace with the index of the desired sample\n",
    "\n",
    "sample = np.expand_dims(X_test1[sample_index], axis=0) \n",
    "\n",
    "y_pred = model.predict(sample)\n",
    "\n",
    "print('Prediction:', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_test[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 19 04:48:42 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX 6000...  On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 30%   37C    P8    21W / 300W |  47843MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX 6000...  On   | 00000000:61:00.0 Off |                  Off |\n",
      "| 30%   33C    P8    26W / 300W |    639MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   1749034      C   /bin/python                     47832MiB |\n",
      "|    1   N/A  N/A   1749034      C   /bin/python                       628MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
